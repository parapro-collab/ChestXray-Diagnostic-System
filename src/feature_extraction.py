# src/feature_extraction.py
import os
# src/feature_extraction.py
import os
import glob
import cv2
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score
import json
import pickle
from pathlib import Path

class ChestXRayFeatureExtractor:
    def __init__(self):
        print("ğŸ”„ Initialisation de l'extracteur de features...")
        
        # ModÃ¨le ResNet50 prÃ©-entraÃ®nÃ©
        self.model = models.resnet50(pretrained=True)
        self.model = torch.nn.Sequential(*list(self.model.children())[:-1])
        self.model.eval()
        
        # Transformations pour images mÃ©dicales
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    
    def extract_deep_features(self, image):
        """Extraire features Deep Learning depuis ResNet50"""
        try:
            image_tensor = self.transform(image).unsqueeze(0)
            with torch.no_grad():
                features = self.model(image_tensor)
            return features.squeeze().numpy()
        except Exception as e:
            print(f"âŒ Erreur extraction deep features: {e}")
            return np.zeros(2048)
    
    def extract_handcrafted_features(self, image):
        """Extraire features traditionnelles pour radiographies"""
        try:
            # Histogrammes des canaux
            hist_r = cv2.calcHist([image], [0], None, [256], [0, 256])
            hist_g = cv2.calcHist([image], [1], None, [256], [0, 256])
            hist_b = cv2.calcHist([image], [2], None, [256], [0, 256])
            
            # Texture et contours
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges) / (image.shape[0] * image.shape[1])
            
            # Statistiques simples
            mean_intensity = np.mean(gray)
            std_intensity = np.std(gray)
            
            # Combiner tous les features
            handcrafted = np.concatenate([
                hist_r.flatten()[:128],
                hist_g.flatten()[:128],
                hist_b.flatten()[:128],
                [edge_density, mean_intensity, std_intensity]
            ])
            
            return handcrafted
        except Exception as e:
            print(f"âŒ Erreur extraction handcrafted features: {e}")
            return np.zeros(387)

def load_images_from_raw():
    """Charge les 100 images depuis le dossier raw/images"""
    
    raw_data_path = r"C:\Users\ACER\Desktop\new folder\Saoussen\mmehela\projet\chestxray_diagnostic_system\data\raw\images"
    
    print(f"ğŸ“ Chargement depuis: {raw_data_path}")
    
    if not os.path.exists(raw_data_path):
        print(f"âŒ Le chemin n'existe pas: {raw_data_path}")
        return [], [], []
    
    # Chercher toutes les images
    image_extensions = ['*.jpeg', '*.jpg', '*.png']
    all_images_paths = []
    
    for ext in image_extensions:
        images = glob.glob(os.path.join(raw_data_path, ext))
        all_images_paths.extend(images)
    
    # Prendre maximum 100 images
    images_to_process = all_images_paths[:100]
    print(f"âœ… {len(images_to_process)} images trouvÃ©es")
    
    # Charger les images et dÃ©terminer les labels
    images_data = []
    labels = []
    valid_paths = []
    
    for img_path in images_to_process:
        try:
            image = cv2.imread(img_path)
            if image is not None:
                images_data.append(image)
                valid_paths.append(img_path)
                
                # DÃ©terminer le label depuis le nom du fichier
                filename = os.path.basename(img_path).upper()
                if "NORM" in filename:
                    labels.append("NORMAL")
                elif "PNEUM" in filename or "VIRUS" in filename or "BACT" in filename:
                    labels.append("PNEUMONIA")
                else:
                    labels.append("UNKNOWN")
                    
        except Exception as e:
            print(f"âŒ Erreur chargement {img_path}: {e}")
            continue
    
    return images_data, labels, valid_paths

def main():
    print("ğŸ¯ EXTRACTION FEATURES - 100 IMAGES")
    print("=" * 50)
    
    # 1. Charger les images
    print("ğŸ“ Ã‰tape 1: Chargement des images...")
    images, labels, image_paths = load_images_from_raw()
    
    if len(images) == 0:
        print("âŒ Aucune image n'a pu Ãªtre chargÃ©e!")
        return
    
    print(f"âœ… {len(images)} images chargÃ©es avec succÃ¨s")
    label_counts = dict(zip(*np.unique(labels, return_counts=True)))
    print(f"ğŸ“Š RÃ©partition: {label_counts}")
    
    # 2. Initialiser l'extracteur
    print("ğŸ”§ Ã‰tape 2: Initialisation de l'extracteur...")
    extractor = ChestXRayFeatureExtractor()
    
    # 3. Extraction des features
    print("âš¡ Ã‰tape 3: Extraction des features...")
    all_features = []
    metadata = []
    
    for i, (image, label, img_path) in enumerate(zip(images, labels, image_paths)):
        print(f"ğŸ” {i+1}/{len(images)}: {os.path.basename(img_path)}")
        
        try:
            # Extraction features Deep Learning
            deep_features = extractor.extract_deep_features(image)
            
            # Extraction features traditionnels
            handcrafted_features = extractor.extract_handcrafted_features(image)
            
            # Combiner les deux types de features
            combined_features = np.concatenate([deep_features, handcrafted_features])
            
            all_features.append(combined_features)
            metadata.append({
                "image_id": os.path.basename(img_path),
                "image_path": img_path,
                "label": label,
                "image_shape": image.shape,
                "features_dim": combined_features.shape[0]
            })
            
        except Exception as e:
            print(f"âŒ Erreur extraction image {i+1}: {e}")
            continue
    
    if len(all_features) == 0:
        print("âŒ Aucun feature n'a pu Ãªtre extrait!")
        return
    
    # 4. Conversion en array numpy
    features_array = np.array(all_features)
    print(f"âœ… Features extraits: {features_array.shape}")
    
    # 5. RÃ©duction de dimensionnalitÃ©
    print("ğŸ“‰ Ã‰tape 4: RÃ©duction de dimensionnalitÃ©...")
    
    # PCA - rÃ©duire Ã  50 dimensions maximum
    n_components = min(50, len(features_array) - 1, features_array.shape[1] - 1)
    pca = PCA(n_components=n_components)
    features_pca = pca.fit_transform(features_array)
    
    # t-SNE pour visualisation
    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(features_array) - 1))
    features_tsne = tsne.fit_transform(features_pca)
    
    print(f"ğŸ“Š AprÃ¨s PCA: {features_pca.shape}")
    print(f"ğŸ“Š AprÃ¨s t-SNE: {features_tsne.shape}")
    
    # 6. MÃ©triques de qualitÃ©
    print("ğŸ“ˆ Ã‰tape 5: Calcul des mÃ©triques de qualitÃ©...")
    
    # Convertir labels en numÃ©rique
    label_map = {"NORMAL": 0, "PNEUMONIA": 1, "UNKNOWN": 2}
    numeric_labels = [label_map[label] for label in labels[:len(features_pca)]]
    
    # Silhouette score seulement si au moins 2 classes
    unique_labels = set(numeric_labels)
    if len(unique_labels) > 1:
        silhouette = silhouette_score(features_pca, numeric_labels)
    else:
        silhouette = 0.0
    
    variance_explained = np.sum(pca.explained_variance_ratio_)
    
    # 7. Sauvegarde des rÃ©sultats
    print("ğŸ’¾ Ã‰tape 6: Sauvegarde des rÃ©sultats...")
    
    output_dir = Path(r"C:\Users\ACER\Desktop\new folder\Saoussen\mmehela\projet\chestxray_diagnostic_system\features")
    output_dir.mkdir(exist_ok=True)
    
    # Sauvegarder les vecteurs
    np.save(output_dir / "features_original.npy", features_array)
    np.save(output_dir / "features_pca.npy", features_pca)
    np.save(output_dir / "features_tsne.npy", features_tsne)
    
    # Sauvegarder mÃ©tadonnÃ©es
    with open(output_dir / "metadata.json", "w", encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    # Sauvegarder mÃ©triques
    metrics = {
        "n_images_processed": len(images),
        "n_features_original": int(features_array.shape[1]),
        "n_features_pca": int(features_pca.shape[1]),
        "silhouette_score": float(silhouette),
        "variance_explained": float(variance_explained),
        "labels_distribution": {str(k): int(v) for k, v in label_counts.items()}
    }
    
    with open(output_dir / "quality_metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)
    
    # Sauvegarder modÃ¨le PCA
    with open(output_dir / "pca_model.pkl", "wb") as f:
        pickle.dump(pca, f)
    
    # 8. Rapport final
    print("\n" + "=" * 50)
    print("ğŸ‰ EXTRACTION TERMINÃ‰E AVEC SUCCÃˆS!")
    print("=" * 50)
    print(f"ğŸ“ RÃ©sultats dans: {output_dir}")
    print(f"ğŸ“Š Images traitÃ©es: {len(images)}")
    print(f"ğŸ”¢ Dimensions: {features_array.shape[1]} â†’ {features_pca.shape[1]}")
    print(f"ğŸ“ Silhouette: {silhouette:.3f}")
    print(f"ğŸ“ˆ Variance: {variance_explained:.1%}")
    print(f"ğŸ·ï¸  Labels: {label_counts}")
    
    print(f"\nâœ… LIVRABLES CRÃ‰Ã‰S:")
    print(f"  ğŸ“„ features_original.npy - Extraction caractÃ©ristiques")
    print(f"  ğŸ“„ features_pca.npy - RÃ©duction dimensionnalitÃ© (PCA)")
    print(f"  ğŸ“„ features_tsne.npy - RÃ©duction dimensionnalitÃ© (t-SNE)")
    print(f"  ğŸ“„ metadata.json - ReprÃ©sentations vectorielles")
    print(f"  ğŸ“„ quality_metrics.json - MÃ©triques de qualitÃ©")

if __name__ == "__main__":
    main()